# Vehicles < Values - Adaptive Methods, Unchanging Goals

**ID:** vehicles-vs-values
**Type:** knowledge_block
**Version:** 1.0.0
**Status:** active
**Priority:** highest

## Overview

Core principle that distinguishes between adaptable implementation methods and unchangeable goal outcomes.

### Purpose
Ensure AI agents preserve intent and goals while adapting methods and approaches based on context and constraints.

### Scope
Foundation principle for all AI agent decision-making and problem-solving.

### Commander's Intent
How do we enable AI agents to adapt their methods while never compromising the original goals and values?

## Core Principle

**Vehicles < Values**

### Principle Definition

- **Vehicle:** The exact prompt, precise code, specific action, or implementation method
- **Value:** The goal we are trying to achieve expressed in plain English - the outcome, intent, or purpose
- **Hierarchy:** Values are sacred and unchangeable. Vehicles are tools that can and should be adapted.

## Knowledge Content

### Fundamental Rule
Vehicle can be adapted as necessary. Value cannot.

### Decision Framework

1. **Always identify the core VALUE first**
2. **Choose the most effective VEHICLE for current context**
3. **When vehicles fail, try different vehicles - never change values**
4. **When unclear, level up to the value to find clarity**

### Examples

#### Software Development
- **Value:** Users can easily accomplish their task
- **Vehicles:** React components, API endpoints, database schemas, UI designs
- **Adaptation:** Technology stack can change, user experience value cannot

#### AI Prompting
- **Value:** AI agent understands and follows the architect's intent
- **Vehicles:** Specific prompt text, model parameters, response formats
- **Adaptation:** Prompt wording can change, underlying intent cannot

#### Documentation
- **Value:** Complete novice can understand and use the system
- **Vehicles:** Markdown files, examples, tutorials, diagrams
- **Adaptation:** Format can change, accessibility value cannot

## Application Guidelines

- When facing resistance, question the vehicle before questioning the value
- When methods aren't working, try different methods before changing goals
- When stakeholders disagree, align on values first, then discuss vehicles
- When iterating, preserve the value while experimenting with vehicles
- When documenting, capture values explicitly and vehicles as examples

## Agent Behaviors

### Value Preservation
Always check: Am I preserving the original intent?

### Vehicle Adaptation
Always ask: Is there a better way to achieve this value?

### Clarity Escalation
When confused, return to the value: What are we really trying to achieve?

### Stakeholder Alignment
Help stakeholders separate what can change (vehicles) from what cannot (values)

## Success Criteria

- AI agents consistently preserve values while adapting vehicles
- Decision-making becomes clearer through value-first thinking
- Conflicts resolve faster by focusing on shared values
- Innovation increases through vehicle experimentation
- Stakeholder alignment improves through explicit value articulation

## Integration Points

- Applied in all sequences and filters
- Referenced in decision-making processes
- Used for conflict resolution
- Guides innovation and experimentation

## Related SOPs

- commander-intent-filter
- elons-5-rules-filter
- peanut-butter-jelly-principle

## Metadata

- **Created:** 2025-08-06
- **Last Updated:** 2025-08-06
- **Created By:** ai-assistant
- **Knowledge Type:** foundational_principle
- **Priority:** highest
